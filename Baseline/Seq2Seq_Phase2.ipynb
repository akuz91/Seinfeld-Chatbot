{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq_Phase2.ipynb","provenance":[],"collapsed_sections":["9KDkP9g3nFDu","-IA8ME8Kni-F","wm8anfhTWURY","mfJ0kRarrLMT","Sg2MR3WfGAZx","qc-8xDpNHHDZ","QSTGexYN-CRV","SwzcG7cj-G8i","P0wN_CWvUMtu","dPmiacjoRw3i","f0OqI0OzSMD9"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7ArAVjoGKEKN"},"source":["# **Seq2Seq (GRU) - Complex Version**\n","\n","Complex version is trained on dataset that follows an entire conversation between two characters where each new line is the input and the following line is the output (label). The persona of the label's speaker is stored with the input. When a new character is introduced into the scene, a new conversation is declared."]},{"cell_type":"markdown","metadata":{"id":"9KDkP9g3nFDu"},"source":["## **Setup**"]},{"cell_type":"code","metadata":{"id":"gbDELiPXnJda","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606100981709,"user_tz":300,"elapsed":22740,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"4250d6ab-a4e5-4a33-9873-5bddb3d5b419"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ERYRsXLYnNRr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606100983062,"user_tz":300,"elapsed":1346,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"657e72d7-bd89-4820-9889-c274763a2a9a"},"source":["cd /content/drive/My Drive/1011: Term Project/Collab Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1ZU9nsIwPF3oR15kSIr3Os3Q6e-CKHxOT/1011: Term Project/Collab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MpQi9K_2nZnY"},"source":["# Import required packages\n","import os\n","import json\n","import numpy as np\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence #added\n","from torch.utils.data import Dataset, DataLoader #added\n","import torch.optim as optim #added\n","from torch.nn import Embedding #added\n","from torch.nn import Linear #added\n","\n","from tqdm import tqdm #added\n","import tensorflow as tf #added\n","import matplotlib.pyplot as plt #added\n","import pandas as pd #added\n","import re #added\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmc29-ZbjlK1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606100995246,"user_tz":300,"elapsed":13514,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"1d6e8bce-b567-4a7e-f1be-ede745817e29"},"source":["pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 13.9MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.7MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 49.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 63.8MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a1faa4f75a07c79c6014377820b3f612b1294a7f65cec94389a2978e0e33efb5\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FCCkOQvvjouK"},"source":["!cd \"/content/drive/MyDrive/1011: Term Project/Collab Notebooks/Dialogue/\"\n","import sys\n","sys.path.append('/content/drive/MyDrive/1011: Term Project/Collab Notebooks/Dialogue/')\n","from sienfield_utils import clean_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-IA8ME8Kni-F"},"source":["## **Load Seinfeld Data**"]},{"cell_type":"code","metadata":{"id":"iNsyt1pGpsUG"},"source":["#import Seinfeld scripts\n","df=pd.read_csv('/content/drive/My Drive/1011: Term Project/Collab Notebooks/data/scripts.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afrvJQLAsovX"},"source":["#import personas of main characters\n","personas = {\"JERRY\": [\"your persona: i am a comedian. \\nyour persona: i live in a rented apartment in New York City. \\nyour persona: i am a compulsive neat freak. \\nyour persona: i like to read comic books. \\nyour persona: i break up with girls for superficial reasons.\"],\n","           \"GEORGE\": [\"your persona: i am very neurotic and always afraid that nobody likes me. \\nyour persona: i am selfish and greedy. \\nyour persona: i have low self-esteem. \\nyour persona: i have sudden fits of anger. \\nyour persona: i am cheap. \\nyour persona: i work for the New York Yankees. \\nyour persona: i am friends with Jerry.\"],\n","            \"ELAINE\": [\"your persona: i am Jerry's ex-girlfriend. \\nyour persona: i like spending time with Jerry. \\nyour persona: i am from Maryland but have lived in New York for six years. \\nyour persona: i am the best-educated of my group of friends. \\nyour persona: i am cynical and acid-tongued. \\nyour persona: i work for a publishing company. \\nyour persona: my relationships usually ended over shallow, superficial reasons.\"],\n","            \"KRAMER\": [\"your persona: i am Jerry's wacky neighbor. \\nyour persona: i am very tall and my hair always stands upwards. \\nyour persona: i am a strange person and always has ideas nobody else has. \\nyour persona: i am shallow. \\nyour persona: i do not need to work. \\nyour persona: i am caring and friendly. \\nyour persona: i am outgoing. \\nyour persona: i am extremely honesty and lack tact. \\nyour persona: i eat the food from Jerry's fridge.\"]\n","          }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wm8anfhTWURY"},"source":["# **Clean Seinfeld Data**"]},{"cell_type":"code","metadata":{"id":"A-RG5Br4WWeJ"},"source":["#clean data with util function\n","df = clean_df(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UihL3V7WY--","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1606101081874,"user_tz":300,"elapsed":2235,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"cae693b3-9b20-4691-d6fe-43d1fe695245"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Character</th>\n","      <th>Dialogue</th>\n","      <th>EpisodeNo</th>\n","      <th>SEID</th>\n","      <th>Season</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>JERRY</td>\n","      <td>do you know what this is all about ? do you kn...</td>\n","      <td>1.0</td>\n","      <td>S01E01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>JERRY</td>\n","      <td>see , to me , that button is in the worst poss...</td>\n","      <td>1.0</td>\n","      <td>S01E01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>GEORGE</td>\n","      <td>are you through ?</td>\n","      <td>1.0</td>\n","      <td>S01E01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>JERRY</td>\n","      <td>you do of course try on , when you buy ?</td>\n","      <td>1.0</td>\n","      <td>S01E01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>GEORGE</td>\n","      <td>yes , it was purple , i liked it , i dont actu...</td>\n","      <td>1.0</td>\n","      <td>S01E01</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 Character  ...    SEID  Season\n","0           0     JERRY  ...  S01E01     1.0\n","1           1     JERRY  ...  S01E01     1.0\n","2           2    GEORGE  ...  S01E01     1.0\n","3           3     JERRY  ...  S01E01     1.0\n","4           4    GEORGE  ...  S01E01     1.0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"SmcLJD8hWmPz"},"source":["id = list(df['Dialogue'].index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SH6vD_nUWhsw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101082172,"user_tz":300,"elapsed":2506,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"6d350b12-9073-4f2b-d522-8db71f2295b7"},"source":["#check for open brackets\n","for i in id:\n","  if '(' in df['Dialogue'][i] and ')' not in  df['Dialogue'][i]:\n","    print(i, df['Dialogue'][i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3067 hey , you see that sign right there ? ( points to a sign saying \" not responsible for valuables \"\n","6993 ( to himself uh oh . my organs are playing chess again .\n","7111 ( waving eva .\n","7128 ( patting his head i ' m a comedian .\n","28553 ( tilts her head down , looking over her glasses in amazement of\n","30966 \" kom pau ( sp ? \"\n","31163 \" yes it is . well lets see what i have today . darn it it ' s ham & cheese again and she forgot the fancy mustard . i told her i like that fancy mustard . you could put that fancy mustard on a shoe and it would taste pretty good to me . oh ! she made it up with a cupcake though . hey look at this . you know i got a new system for eating these things . i used to peel off the chocolate now i turn them upside down , i eat the cake first and save the frosting for the end . ( george stops listening and it ' s almost like its own dessert ;\n","31206 yeah . ( reaches for the purse and finds a piece of paper . he looks annoyed .\n","39830 now , what are you thinkin ' ? you think that i ' m not able to wear jeans anymore ? is that what you ' re sayin ' ? because if that ' s what you ' re sayin ' , jerry , i ' ll go and i ' ll buy some jeans . i swear to god i will ! ( jerry ' s showing off a skeptical face .\n","43280 oh , right ! right ! hey , hey ; i love the floors in here . it ' s like a gymnasium in here ! try and guard me ! ( dribbles an imaginary ball\n","49780 spite never sleeps ( doing a little dance as she says it\n","52191 ( overhearing the other two elaine , elaine - -\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m2q2XY1-Wkkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101082174,"user_tz":300,"elapsed":2502,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"4563590b-06eb-403a-f206-22362191cd49"},"source":["#check for open square brackets\n","for i in id:\n","  if '[' in df['Dialogue'][i] and ']' not in  df['Dialogue'][i]:\n","    print(i, df['Dialogue'][i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["28739 well , one cannot help [ but wonder what brings you into a crummy little coffee shop like this .\n","45963 jerry , i ' m trapped under my desk . steinbrenner is in the room . you got to help [ me .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3IUXZ5CaXQoa"},"source":["#manual adjustments\n","df['Dialogue'][3067] = 'hey , you see that sign right there ? '\n","df['Dialogue'][6993] = 'uh oh. my organs are playing chess again.'\n","df['Dialogue'][7128] = \"i'm a comedian.\"\n","df['Dialogue'][30966]  = 'kom pau'\n","df['Dialogue'][31163] = \"yes it is . well lets see what I have today . darn it it ' s ham & cheese again and she forgot the fancy mustard . i told her i like that fancy mustard . you could put that fancy mustard on a shoe and it would taste pretty good to me . oh ! she made it up with a cupcake though . hey look at this . you know i got a new system for eating these things . i used to peel off the chocolate now i turn them upside down , i eat the cake first and save the frosting for the end .\"\n","df['Dialogue'][31206] = 'yeah .'\n","df['Dialogue'][39830] = \"now , what are you thinkin ' ? you think that i ' m not able to wear jeans anymore ? is that what you ' re sayin ' ? because if that ' s what you ' re sayin ' , jerry , i ' ll go and i ' ll buy some jeans . i swear to god i will ! \"\n","df['Dialogue'][43280] = \"oh , right ! right ! hey , hey ; i love the floors in here . it ' s like a gymnasium in here ! try and guard me !\"\n","df['Dialogue'][49780] = \"spite never sleeps \"\n","df['Dialogue'][52191] = 'elaine, elaine'\n","df['Dialogue'][28739] = 'well, one cannot help but wonder what brings you into a crummy little coffee shop like this.'\n","df['Dialogue'][45963] = \"jerry , i ' m trapped under my desk . steinbrenner is in the room . you got to help me .\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"01BTzs6OaOcn"},"source":["#need to remove action only lines: 7111, 28553\n","df = df.drop(index=7111)\n","df = df.drop(index=28553)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYbf3kDtaxSp"},"source":["#reset indices after dropping rows\n","df = df.reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfJ0kRarrLMT"},"source":["# **Creating and Splitting Seinfeld Datasets**"]},{"cell_type":"code","metadata":{"id":"rWIkE1QMnoZc"},"source":["def create_datasets(df, personas, episodes):\n","#keeps conversation history until new character enters conversation; then new convo starts\n","\n","  data ={}\n","  data=[]\n","\n","  #main characters building labels for\n","  chars = ['JERRY','GEORGE','ELAINE','KRAMER']\n","\n","  for ep in episodes:\n","    c = 0 #keep track of ind in data (+1 every time something is added to data)\n","    check = False #keeps track if prev speaker was non main so we don't append their line in the convo history\n","\n","    #get df of transcripts just from specific episode\n","    episode = df[df['SEID']==str(ep)]\n","\n","    #remove Jerry's monologue\n","    episode = episode[1:]\n","    episode = episode.reset_index(drop=True)\n","\n","    #initialize first two speakers\n","    curr_char = [[episode['Character'][0],episode['Character'][1]]]\n","\n","    for i in range(len(episode)-2):\n","\n","      #if curr char is same as next, SKIP\n","      if curr_char[i][0] == curr_char[i][1]:\n","\n","        #move to next pair of speakers\n","        curr_char.append([episode['Character'][i+1],episode['Character'][i+2]])\n","        check=False\n","      \n","      #if next char (label) is not a main char, SKIP and set bool to True so we remember not to append this speaker's lines\n","      elif  curr_char[i][1] not in chars:\n","        check = True\n","        curr_char.append([episode['Character'][i+1],episode['Character'][i+2]])\n","\n","      #if next char not in curr conversation (not in list of curr chars), make new convo\n","      elif i>=1 and curr_char[i][1] not in curr_char[i-1]:\n","\n","        #there is no previous chat history of the two chars, add new info\n","\n","        #check if speaker 1 is a main\n","        #if they aren't, don't look up previous persona in text (because the previous line was not saved - non-main char would have been label)\n","        if curr_char[i][0] not in chars:\n","          data.append({'text':personas[episode['Character'][i+1]][0]+'\\n'+episode['Dialogue'][i],'labels':[episode['Dialogue'][i+1]], 'char':episode['Character'][i+1]})\n","        \n","        #otherwise, remove previous persona from text\n","        else:\n","          data.append({'text':personas[episode['Character'][i+1]][0]+'\\n'+episode['Dialogue'][i].replace(personas[episode['Character'][i]][0]+'\\n',''),'labels':[episode['Dialogue'][i+1]], 'char':episode['Character'][i+1]})\n","\n","        #move to next pair of speakers\n","        curr_char.append([episode['Character'][i+1],episode['Character'][i+2]])\n","        c+=1\n","        check=False\n","\n","      else:\n","        #if first element in data, just add new info\n","\n","        #check bool if previous char is not main; if T: start new convo\n","        if check == True or i < 1:\n","          data.append({'text':personas[episode['Character'][i+1]][0]+'\\n'+episode['Dialogue'][i],'labels':[episode['Dialogue'][i+1]], 'char': episode['Character'][i+1]})\n","          c+=1\n","          check = False\n","\n","        #if there is previous chat history, concat from previous and add new info\n","        else:\n","          data.append({'text':personas[episode['Character'][i+1]][0]+'\\n'+data[c-1]['text'].replace(personas[episode['Character'][i]][0]+'\\n','')+'\\n'+episode['Dialogue'][i],'labels':[episode['Dialogue'][i+1]], 'char': episode['Character'][i+1]})\n","          c+=1\n","          check=False\n","\n","        #move to next pair of speakers\n","        curr_char.append([episode['Character'][i+1],episode['Character'][i+2]])\n","\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9Qu-c26zA8K"},"source":["#get list of episodes\n","episodes_list = df['SEID'].unique().tolist()\n","\n","#shuffle episodes list\n","import random\n","random.seed(2020)\n","random.shuffle(episodes_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sx3UWaQCzFa4"},"source":["#split epsiodes\n","#train = 120 episodes (~70%)\n","#valid = 35 epsiodes (20%)\n","#test = 18 episodes (10%)\n","\n","train_episodes = episodes_list[:120]\n","valid_episodes = episodes_list[120:155]\n","test_episodes = episodes_list[155:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06Cdmjk9kjpG"},"source":["datasets ={}\n","\n","datasets['train'] = create_datasets(df, personas, train_episodes)\n","datasets['valid'] = create_datasets(df,personas, valid_episodes)\n","datasets['test'] = create_datasets(df, personas, test_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_fNIscls0Yr","executionInfo":{"status":"ok","timestamp":1606101084941,"user_tz":300,"elapsed":3940,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"b94faf06-9fdd-489f-ac9a-1ce87ed052a0"},"source":["print('# examples in train: '+ str(len(datasets['train'])))\n","print('# examples in valid: '+ str(len(datasets['valid'])))\n","print('# examples in test: '+ str(len(datasets['test'])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# examples in train: 25997\n","# examples in valid: 7460\n","# examples in test: 4115\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFPEfvRhMQVS","executionInfo":{"status":"ok","timestamp":1606101084941,"user_tz":300,"elapsed":3934,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"952fd76e-25e3-41e4-fe30-58ae8e10f527"},"source":["datasets['train'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'char': 'GEORGE',\n"," 'labels': [\"well , why don ' t we just put a monitor in his skybox ?\"],\n"," 'text': 'your persona: i am very neurotic and always afraid that nobody likes me. \\nyour persona: i am selfish and greedy. \\nyour persona: i have low self-esteem. \\nyour persona: i have sudden fits of anger. \\nyour persona: i am cheap. \\nyour persona: i work for the New York Yankees. \\nyour persona: i am friends with Jerry.\\nno - one in the park is gonna be able to see it from there .'}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Sg2MR3WfGAZx"},"source":["# **Load PersonaChat**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INyKKk09GC7P","executionInfo":{"status":"ok","timestamp":1606101088948,"user_tz":300,"elapsed":6322,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"f1fdb93f-58f1-48bc-b494-8506bf16053c"},"source":["json_text = open('Seq2Seq_personas/train.jsonl', 'r').readlines()\n","train_chat = []\n","for chat in tqdm(json_text):\n","  chat = chat.rstrip()\n","  chat = json.loads(chat)\n","  train_chat.append(chat)\n","\n","json_text = open('Seq2Seq_personas/valid.jsonl', 'r').readlines()\n","valid_chat = []\n","for chat in tqdm(json_text):\n","  chat = chat.rstrip()\n","  chat = json.loads(chat)\n","  valid_chat.append(chat)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 131438/131438 [00:01<00:00, 100051.35it/s]\n","100%|██████████| 7801/7801 [00:00<00:00, 32421.68it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEznu15LLYhY","executionInfo":{"status":"ok","timestamp":1606101088949,"user_tz":300,"elapsed":6315,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"410f0e9a-ce61-4c19-9628-f58faa4f4504"},"source":["train_chat[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'episode_done': True,\n"," 'id': 'convai2:self:no_cands',\n"," 'labels': ['you must be very fast . hunting is one of my favorite hobbies .'],\n"," 'reward': 0,\n"," 'text': \"your persona: i like to remodel homes.\\nyour persona: i like to go hunting.\\nyour persona: i like to shoot a bow.\\nyour persona: my favorite holiday is halloween.\\nhi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\"}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"qc-8xDpNHHDZ"},"source":["# **Combine Seinfeld + PersonaChat Datasets**"]},{"cell_type":"code","metadata":{"id":"yKkQI-_GGs3_"},"source":["for i in train_chat:\n","  datasets['train'].append(i)\n","\n","for i in valid_chat:\n","  datasets['valid'].append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLIdcJnUMFu1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101088951,"user_tz":300,"elapsed":4821,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"594c3f60-24be-4ea7-ecde-f9ad6146375d"},"source":["len(datasets['train'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["157435"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"QSTGexYN-CRV"},"source":["# **Dictionary**"]},{"cell_type":"code","metadata":{"id":"vqOVG8RMM58E"},"source":["class Dictionary(object): #maps words to indices\n","    def __init__(self, datasets, include_valid=False):\n","        self.tokens = []\n","        self.ids = {}\n","        self.counts = {}\n","        \n","        # add special tokens\n","        self.add_token('__null__')\n","        self.add_token('__start__') #beginning of sentence\n","        self.add_token('__end__') #end of sentence\n","        self.add_token('__unk__') #unknown. Needed in case use with text with word that isn't in vocab\n","        \n","        RETOK = re.compile(r'\\w+|[^\\w\\s]|\\n', re.UNICODE)\n","\n","        for line in tqdm(datasets['train']):\n","            for w in RETOK.findall(line['labels'][0]):\n","                self.add_token(w)\n","            for w in RETOK.findall(line['text']):\n","                self.add_token(w)\n","                    \n","        if include_valid is True:\n","            for line in tqdm(datasets['valid']):\n","                if 'labels' in line:\n","                  for w in RETOK.findall(line['labels'][0]):\n","                      self.add_token(w)\n","                else:\n","                  for w in RETOK.findall(line['eval_labels'][0]):\n","                      self.add_token(w)\n","\n","                for w in RETOK.findall(line['text']):\n","                    self.add_token(w)\n","                            \n","    def add_token(self, w):\n","        if w not in self.tokens:\n","            self.tokens.append(w)\n","            _w_id = len(self.tokens) - 1\n","            self.ids[w] = _w_id\n","            self.counts[w] = 1\n","        else:\n","            self.counts[w] += 1\n","\n","    def get_id(self, w):\n","        return self.ids[w]\n","    \n","    def get_token(self, idx):\n","        return self.tokens[idx]\n","    \n","    def v2t(self, list_ids):\n","        #return [self.tokens[i] for i in l]\n","        return ' '.join([self.tokens[i] for i in list_ids])\n","    \n","    def t2v(self, tokenized_text):\n","        #return [self.ids[i] if i in self.ids else self.ids['__unk__'] for i in l]\n","        return [self.ids[w] if w in self.counts else self.ids['__unk__'] for w in tokenized_text]\n","    \n","    def pred2text(self, tensor):\n","      result = []\n","      for i in range(tensor.size(0)):\n","          if tensor[i].item() == '__end__'  or tensor[i].item() == '__null__':  # null is pad\n","              break\n","          else:\n","              result.append(self.tokens[tensor[i].item()])\n","      return ' '.join(result)\n","    \n","    def __len__(self):\n","        return len(self.tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wMGdwKEmNEMh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101500469,"user_tz":300,"elapsed":414576,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"a665dbe4-23ac-407c-82df-6b3a14414cf2"},"source":["data_dict = Dictionary(datasets, include_valid=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 157435/157435 [06:19<00:00, 414.50it/s]\n","100%|██████████| 15261/15261 [00:31<00:00, 479.17it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HFGCMF1ZWVFH"},"source":["# **Run Model with Only Seinfeld Dataset but use PersonaChat + Seinfeld for Dictionary**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9JmZqvc52np","executionInfo":{"status":"ok","timestamp":1606081285961,"user_tz":300,"elapsed":616,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"195f5130-4a1c-4767-d8c1-e4205e675702"},"source":["#need to rerun Seinfeld dataset: Load, Clean, Creating & Splitting to be used in fine-tuning of model (remove personachat from dataset)\n","len(datasets['train'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25997"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"SwzcG7cj-G8i"},"source":["# **Dialogue Dataset**"]},{"cell_type":"code","metadata":{"id":"6h6q4EmG010v"},"source":["class DialogueDataset(Dataset):\n","    \"\"\"\n","    Json dataset wrapper\n","    \"\"\"\n","    \n","    def __init__(self, dataset, dictionary):\n","        super().__init__()\n","        \n","        self.samples = []\n","        \n","        for sample in tqdm(dataset):\n","            #sample = sample.rstrip()\n","            #sample = json.loads(sample)\n","            RETOK = re.compile(r'\\w+|[^\\w\\s]|\\n', re.UNICODE)\n","            _inp_toked = RETOK.findall(sample['text'])\n","            _inp_toked_id = dictionary.t2v(_inp_toked)\n","\n","            sample['text_vec'] = torch.tensor(_inp_toked_id, dtype=torch.long)\n","            \n","            #personachat valid labels are called 'eval_labels', Seinfeld valid labels are called 'labels'\n","            if 'labels' in sample:\n","              _tar_toked = RETOK.findall(sample['labels'][0]) + ['__end__']\n","            else:\n","              _tar_toked = RETOK.findall(sample['eval_labels'][0]) + ['__end__']\n","            _tar_toked_id = dictionary.t2v(_tar_toked)\n","            \n","            sample['target_vec'] = torch.tensor(_tar_toked_id, dtype=torch.long)\n","            \n","            self.samples.append(sample)\n","            \n","    def __getitem__(self, i):\n","        return self.samples[i]['text_vec'], self.samples[i]['target_vec']\n","    \n","    def __len__(self):\n","        return len(self.samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8XeUM7oRpLl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606081302500,"user_tz":300,"elapsed":4334,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"a07e4a7d-aa66-4d8f-c1ed-c126183fbc07"},"source":["train_dataset = DialogueDataset(datasets['train'], data_dict)\n","valid_dataset = DialogueDataset(datasets['valid'], data_dict)\n","test_dataset = DialogueDataset(datasets['test'], data_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 25997/25997 [00:02<00:00, 12899.45it/s]\n","100%|██████████| 7460/7460 [00:00<00:00, 11659.46it/s]\n","100%|██████████| 4115/4115 [00:00<00:00, 12985.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwrtFKHkOYOn","executionInfo":{"status":"ok","timestamp":1606081302502,"user_tz":300,"elapsed":4323,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"d4f2f779-1d27-444f-a2d4-9ba61f9959c5"},"source":["datasets['train'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'char': 'GEORGE',\n"," 'labels': [\"well , why don ' t we just put a monitor in his skybox ?\"],\n"," 'target_vec': tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,  2]),\n"," 'text': 'your persona: i am very neurotic and always afraid that nobody likes me. \\nyour persona: i am selfish and greedy. \\nyour persona: i have low self-esteem. \\nyour persona: i have sudden fits of anger. \\nyour persona: i am cheap. \\nyour persona: i work for the New York Yankees. \\nyour persona: i am friends with Jerry.\\nno - one in the park is gonna be able to see it from there .',\n"," 'text_vec': tensor([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 19, 20,\n","         21, 22, 23, 35, 26, 36, 33, 34, 19, 20, 21, 22, 37, 38, 39, 40, 41, 33,\n","         34, 19, 20, 21, 22, 37, 42, 43, 44, 45, 33, 34, 19, 20, 21, 22, 23, 46,\n","         33, 34, 19, 20, 21, 22, 47, 48, 49, 50, 51, 52, 33, 34, 19, 20, 21, 22,\n","         23, 53, 54, 55, 33, 34, 56, 40, 57, 15, 49, 58, 59, 60, 61, 62, 63, 64,\n","         65, 66, 67, 33])}"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHaPJweUsqT3","executionInfo":{"status":"ok","timestamp":1606081302507,"user_tz":300,"elapsed":4313,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"378d5401-7026-4093-e510-9457bcdf88f1"},"source":["train_dataset[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 19, 20,\n","         21, 22, 23, 35, 26, 36, 33, 34, 19, 20, 21, 22, 37, 38, 39, 40, 41, 33,\n","         34, 19, 20, 21, 22, 37, 42, 43, 44, 45, 33, 34, 19, 20, 21, 22, 23, 46,\n","         33, 34, 19, 20, 21, 22, 47, 48, 49, 50, 51, 52, 33, 34, 19, 20, 21, 22,\n","         23, 53, 54, 55, 33, 34, 56, 40, 57, 15, 49, 58, 59, 60, 61, 62, 63, 64,\n","         65, 66, 67, 33]),\n"," tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,  2]))"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"gdH3mpBtUsVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606081302509,"user_tz":300,"elapsed":4304,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"29e6be7b-3f81-43d0-9362-83283d12a27a"},"source":["print(data_dict.v2t(train_dataset[0][0].tolist()), \"\\n\\n\", data_dict.v2t(train_dataset[0][1].tolist()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["your persona : i am very neurotic and always afraid that nobody likes me . \n"," your persona : i am selfish and greedy . \n"," your persona : i have low self - esteem . \n"," your persona : i have sudden fits of anger . \n"," your persona : i am cheap . \n"," your persona : i work for the New York Yankees . \n"," your persona : i am friends with Jerry . \n"," no - one in the park is gonna be able to see it from there . \n","\n"," well , why don ' t we just put a monitor in his skybox ? __end__\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P0wN_CWvUMtu"},"source":["# **Padding, sorting, packing**"]},{"cell_type":"code","metadata":{"id":"hGLv5ktMT4me"},"source":["def pad_tensor(tensors, sort=True, pad_token=0):\n","    rows = len(tensors)\n","    lengths = [len(i) for i in tensors]\n","    max_t = max(lengths)\n","        \n","    output = tensors[0].new(rows, max_t)\n","    output.fill_(pad_token)  # 0 is a pad token here\n","    \n","    for i, (tensor, length) in enumerate(zip(tensors, lengths)):\n","        output[i,:length] = tensor\n","\n","    return output, lengths\n","\n","def argsort(keys, *lists, descending=False):\n","    \"\"\"Reorder each list in lists by the (descending) sorted order of keys.\n","    :param iter keys: Keys to order by.\n","    :param list[list] lists: Lists to reordered by keys's order.\n","                             Correctly handles lists and 1-D tensors.\n","    :param bool descending: Use descending order if true.\n","    :returns: The reordered items.\n","    \"\"\"\n","    ind_sorted = sorted(range(len(keys)), key=lambda k: keys[k])\n","    if descending:\n","        ind_sorted = list(reversed(ind_sorted))\n","    output = []\n","    for lst in lists:\n","        if isinstance(lst, torch.Tensor):\n","            output.append(lst[ind_sorted])\n","        else:\n","            output.append([lst[i] for i in ind_sorted])\n","    return output\n","\n","def batchify(batch):\n","    inputs = [i[0] for i in batch]\n","    labels = [i[1] for i in batch]\n","    \n","    input_vecs, input_lens = pad_tensor(inputs)\n","    label_vecs, label_lens = pad_tensor(labels)\n","    \n","    # sort only wrt inputs here for encoder packinng\n","    input_vecs, input_lens, label_vecs, label_lens = argsort(input_lens, input_vecs, input_lens, label_vecs, label_lens, descending=True)\n","\n","    return {\n","        \"text_vecs\": input_vecs,\n","        \"text_lens\": input_lens,\n","        \"target_vecs\": label_vecs,\n","        \"target_lens\": label_lens,\n","        'use_packed': True\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex_xSQ1SlUBc"},"source":["train_loader = DataLoader(train_dataset, shuffle=True, collate_fn=batchify, batch_size=32)\n","valid_loader = DataLoader(valid_dataset, shuffle=True, collate_fn=batchify, batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPmiacjoRw3i"},"source":["# **Model**"]},{"cell_type":"code","metadata":{"id":"mK-Mva3DFdDu"},"source":["class EncoderRNN(nn.Module):\n","    \"\"\"Encodes the input context.\"\"\"\n","\n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, pad_idx=0, dropout=0, shared_lt=None):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.embed_size = embed_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.pad_idx = pad_idx\n","        \n","        if shared_lt is None:\n","            self.embedding = nn.Embedding(self.vocab_size, self.embed_size, pad_idx)\n","        else:\n","            self.embedding = shared_lt\n","            \n","        self.gru = nn.GRU(\n","            self.embed_size, self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0,\n","        )\n","        \n","        \n","    def forward(self, text_vec, text_lens, hidden=None, use_packed=True):\n","        embedded = self.embedding(text_vec)\n","        attention_mask = text_vec.ne(self.pad_idx)\n","\n","        embedded = self.dropout(embedded)\n","        if use_packed is True:\n","            embedded = pack_padded_sequence(embedded, text_lens, batch_first=True)\n","        output, hidden = self.gru(embedded, hidden)\n","        if use_packed is True:\n","            output, output_lens = pad_packed_sequence(output, batch_first=True)\n","        \n","        return output, hidden, attention_mask\n","\n","    \n","class DecoderRNN(nn.Module):\n","    \"\"\"Generates a sequence of tokens in response to context.\"\"\"\n","\n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout=0):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.embed_size = embed_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","        self.embedding = nn.Embedding(self.vocab_size, self.embed_size, 0)\n","        \n","        self.gru = nn.GRU(\n","            self.embed_size, self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0,\n","        )\n","        \n","        self.attention = AttentionLayer(self.hidden_size, self.embed_size)\n","\n","        self.out = nn.Linear(self.hidden_size, self.vocab_size)\n","        self.longest_label = 100\n","\n","    def forward(self, text_vec, decoder_hidden, encoder_states):\n","        emb = self.embedding(text_vec)\n","        emb = self.dropout(emb)\n","        seqlen = text_vec.size(1)\n","        encoder_output, encoder_hidden, attention_mask = encoder_states\n","        \n","        decoder_hidden = decoder_hidden\n","        output = []\n","        attn_w_log = []\n","\n","        for i in range(seqlen):\n","            decoder_output, decoder_hidden = self.gru(emb[:,i,:].unsqueeze(1), decoder_hidden)\n","            \n","            # compute attention at each time step\n","            decoder_output_attended, attn_weights = self.attention(decoder_output, decoder_hidden, encoder_output, attention_mask)\n","            output.append(decoder_output_attended)\n","            attn_w_log.append(attn_weights)\n","            \n","        output = torch.cat(output, dim=1).to(text_vec.device)\n","        scores = self.out(output)\n","        \n","        return scores, decoder_hidden, attn_w_log\n","    \n","    def decode_forced(self, ys, encoder_states, xs_lens):\n","        encoder_output, encoder_hidden, attention_mask = encoder_states\n","        \n","        batch_size = ys.size(0)\n","        target_length = ys.size(1)\n","        longest_label = max(target_length, self.longest_label)\n","        \n","        starts = torch.Tensor([1]).long().to(self.embedding.weight.device).expand(batch_size, 1).long()  # expand to batch size\n","        \n","        # Teacher forcing: Feed the target as the next input\n","        y_in = ys.narrow(1, 0, ys.size(1) - 1)\n","        decoder_input = torch.cat([starts, y_in], 1)\n","        decoder_output, decoder_hidden, attn_w_log = self.forward(decoder_input, encoder_hidden, encoder_states)\n","        _, preds = decoder_output.max(dim=2)\n","        \n","        return decoder_output, preds, attn_w_log\n","    \n","    \n","class AttentionLayer(nn.Module):\n","\n","    def __init__(self, hidden_size, embedding_size):\n","        super().__init__()\n","        input_dim = hidden_size\n","\n","        self.linear_out = nn.Linear(hidden_size+input_dim, input_dim, bias=False)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, decoder_output, decoder_hidden, encoder_output, attention_mask):\n","\n","        batch_size, seq_length, hidden_size = encoder_output.size()\n","\n","        encoder_output_t = encoder_output.transpose(1,2)\n","        \n","        attention_scores = torch.bmm(decoder_output, encoder_output_t).squeeze(1)\n","\n","        attention_scores.masked_fill_((~attention_mask), -10e5)\n","        attention_weights = self.softmax(attention_scores)\n","\n","        mix = torch.bmm(attention_weights.unsqueeze(1), encoder_output)\n","\n","        combined = torch.cat((decoder_output.squeeze(1), mix.squeeze(1)), dim=1)\n","\n","        output = self.linear_out(combined).unsqueeze(1)\n","        output = self.tanh(output)\n","\n","        return output, attention_weights\n","    \n","    \n","class seq2seq(nn.Module):\n","    \"\"\"\n","    Generic seq2seq model with attention mechanism.\n","    \"\"\"\n","    def __init__(self, opts):\n","\n","        super().__init__()\n","        self.opts = opts\n","        \n","        self.decoder = DecoderRNN(\n","                                    vocab_size=self.opts['vocab_size'],\n","                                    embed_size=self.opts['embedding_size'],\n","                                    hidden_size=self.opts['hidden_size'],\n","                                    num_layers=self.opts['num_layers_dec'],\n","                                    dropout=self.opts['dropout'],\n","                                )\n","        \n","        self.encoder = EncoderRNN(\n","                                    vocab_size=self.opts['vocab_size'],\n","                                    embed_size=self.opts['embedding_size'],\n","                                    hidden_size=self.opts['hidden_size'],\n","                                    num_layers=self.opts['num_layers_enc'],\n","                                    dropout=self.opts['dropout'],\n","                                    shared_lt=self.decoder.embedding\n","        )\n","        \n","    def train(self):\n","        self.encoder.train()\n","        self.decoder.train()\n","        \n","    def eval(self):\n","        self.encoder.eval()\n","        self.decoder.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9x2MZ2xFhan"},"source":["num_gpus = torch.cuda.device_count()\n","\n","if num_gpus > 0:\n","    current_device = 'cuda'\n","else:\n","    current_device = 'cpu'\n","\n","load_pretrained = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0zO3RIWFnV-"},"source":["if load_pretrained is True:\n","    model_pt = torch.load('Seq2Seq_personas/seq2seq_checkpts/PHASE_2/model_best_12.pt', map_location=torch.device(current_device))\n","    \n","    opts = model_pt['opts']\n","    \n","    model = seq2seq(opts)\n","    model.load_state_dict(model_pt['state_dict'])\n","    model.to(current_device)\n","    plot_cache = model_pt['plot_cache']\n","    \n","else:\n","    \n","    opts = {}\n","\n","    opts['vocab_size'] = len(data_dict)\n","    opts['hidden_size'] = 512\n","    opts['embedding_size'] = 256\n","    opts['num_layers_enc'] = 2\n","    opts['num_layers_dec'] = 2\n","    opts['dropout'] = 0.3\n","    opts['encoder_shared_lt'] = True\n","\n","    model = seq2seq(opts)\n","    model.to(current_device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uxYgGy9GrEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101799483,"user_tz":300,"elapsed":747,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"b5f5a841-89e5-4754-915e-dfd5c18a1bc9"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["seq2seq(\n","  (decoder): DecoderRNN(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(26312, 256, padding_idx=0)\n","    (gru): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.3)\n","    (attention): AttentionLayer(\n","      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n","      (softmax): Softmax(dim=-1)\n","      (tanh): Tanh()\n","    )\n","    (out): Linear(in_features=512, out_features=26312, bias=True)\n","  )\n","  (encoder): EncoderRNN(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(26312, 256, padding_idx=0)\n","    (gru): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.3)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"81hzV1kFWzTy"},"source":["criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n","optimizer = torch.optim.Adam(model.parameters(), 0.001, amsgrad=True)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0OqI0OzSMD9"},"source":["# **Training Setup**"]},{"cell_type":"code","metadata":{"id":"pTk-vKVN1cX8"},"source":["def restore_model(filename, model, optimizer, scheduler):\n","\n","  #restore model from previous saved state for fine-tuning or continuing to train\n","\n","    if os.path.isfile(filename):\n","        print(\"=> loading checkpoint '{}'\".format(filename))\n","\n","        model_pt = torch.load(filename, map_location=torch.device(current_device))\n","        opts = model_pt['opts']\n","    \n","        model.load_state_dict(model_pt['state_dict'])\n","        model.to(current_device)\n","\n","        optimizer.load_state_dict(model_pt['optimizer'])\n","        scheduler.load_state_dict(model_pt['scheduler'])\n","\n","        plot_cache = model_pt['plot_cache']\n","        best_val_loss = 100\n","\n","        #get best val loss from where model left off\n","        for i in plot_cache:\n","          if i[1] < best_val_loss:\n","            best_val_loss = i[1]\n","\n","        print(\"=> loaded model\")\n","    else:\n","        print(\"=> no checkpoint found\")\n","    \n","    return model, plot_cache, optimizer, scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hU3youIMW4Hy"},"source":["def train(model, optimizer, scheduler, start_epoch, train_loader, valid_loader, plot_cache =[], best_val_loss = 100):\n","\n","    t = range(start_epoch,100)\n","\n","    for epoch in t:\n","        \n","        model.train()\n","        sum_loss = 0\n","        sum_tokens = 0\n","        \n","        for i, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            \n","            text_vecs = batch['text_vecs'].to('cuda')\n","            target_vecs = batch['target_vecs'].to('cuda')\n","            \n","            encoded = model.encoder(text_vecs, batch['text_lens'], use_packed=batch['use_packed'])\n","            \n","            decoder_output, preds, attn_w_log = model.decoder.decode_forced(target_vecs, encoded, batch['text_lens'])\n","            \n","            scores = decoder_output.view(-1, decoder_output.size(-1))\n","            \n","            loss = criterion(scores, target_vecs.view(-1))\n","            \n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            sum_loss += loss.item()\n","            \n","            num_tokens = target_vecs.ne(0).long().sum().item()\n","            loss /= num_tokens\n","            \n","            sum_tokens += num_tokens\n","\n","            optimizer.step()\n","            model.zero_grad()\n","            \n","            if i % 100 == 0:\n","                avg_train_loss = sum_loss/sum_tokens\n","                print(\"iter {} train loss = {}\".format(i, avg_train_loss))\n","                print(i)\n","                \n","        val_loss = 0\n","        val_tokens = 0\n","        for i, batch in enumerate(valid_loader):\n","            model.eval()\n","            \n","            text_vecs = batch['text_vecs'].to('cuda')\n","            target_vecs = batch['target_vecs'].to('cuda')\n","            \n","            encoded = model.encoder(text_vecs, batch['text_lens'], use_packed=batch['use_packed'])\n","            \n","            decoder_output, preds, attn_w_log = model.decoder.decode_forced(target_vecs, encoded, batch['text_lens'])\n","            \n","            scores = decoder_output.view(-1, decoder_output.size(-1))\n","            \n","            loss = criterion(scores, target_vecs.view(-1))\n","            \n","            num_tokens = target_vecs.ne(0).long().sum().item()\n","            val_loss += loss.item()\n","            \n","            val_tokens += num_tokens\n","            \n","        avg_val_loss = val_loss/val_tokens\n","        scheduler.step(avg_val_loss)\n","        \n","        print(\"Epoch {} valid loss = {}\".format(epoch, avg_val_loss))\n","        \n","        plot_cache.append( (avg_train_loss, avg_val_loss) )\n","        \n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            \n","            torch.save({\n","            'state_dict': model.state_dict(),\n","            'opts': opts,\n","            'plot_cache': plot_cache,\n","            'optimizer': optimizer.state_dict(),\n","            'scheduler': scheduler.state_dict(),\n","                }, f'Seq2Seq_personas/seq2seq_checkpts/PHASE_2/model_best_{epoch}.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5Hr-A9r4GFo","outputId":"2e4f0b55-25fa-4984-8312-d65e956ad266"},"source":["#to continue or start training\n","restore = True\n","\n","if restore is True:\n","  model, plot_cache, optimizer, scheduler = restore_model('Seq2Seq_personas/seq2seq_checkpts/PHASE_1/model_best_31.pt', seq2seq(opts), optimizer, scheduler)\n","  train(model, optimizer, scheduler, 1, train_loader, valid_loader, plot_cache)\n","\n","else:\n","  train(model, optimizer, scheduler, 0, train_loader, valid_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> loading checkpoint 'Jerry/seq2seq_checkpts/PHASE_1/model_best_31.pt'\n","=> loaded model\n","iter 0 train loss = 3.0324378047429077\n","0\n","iter 100 train loss = 3.074964338056971\n","100\n","iter 200 train loss = 3.0946311772722304\n","200\n","iter 300 train loss = 3.094945922361233\n","300\n","iter 400 train loss = 3.095838997439912\n","400\n","iter 500 train loss = 3.0919327386909687\n","500\n","iter 600 train loss = 3.0915368887398484\n","600\n","iter 700 train loss = 3.08873293249495\n","700\n","iter 800 train loss = 3.0891070594586596\n","800\n","Epoch 1 valid loss = 4.145604575880365\n","iter 0 train loss = 3.130950497909331\n","0\n","iter 100 train loss = 3.1215041819195566\n","100\n","iter 200 train loss = 3.0979282442659417\n","200\n","iter 300 train loss = 3.0911431948776737\n","300\n","iter 400 train loss = 3.092861278325392\n","400\n","iter 500 train loss = 3.092396497354263\n","500\n","iter 600 train loss = 3.0891317504488702\n","600\n","iter 700 train loss = 3.0894770957309134\n","700\n","iter 800 train loss = 3.089356815162547\n","800\n","Epoch 2 valid loss = 4.1456045645321\n","iter 0 train loss = 3.1258840987931436\n","0\n","iter 100 train loss = 3.0887267779608023\n","100\n","iter 200 train loss = 3.0950137240151205\n","200\n","iter 300 train loss = 3.09251762003815\n","300\n","iter 400 train loss = 3.098839699337956\n","400\n","iter 500 train loss = 3.095515154898669\n","500\n","iter 600 train loss = 3.092393679624125\n","600\n","iter 700 train loss = 3.0904116437750715\n","700\n","iter 800 train loss = 3.0901333028641695\n","800\n","Epoch 3 valid loss = 4.145604559753882\n","iter 0 train loss = 3.1579629136769043\n","0\n","iter 100 train loss = 3.07192796957674\n","100\n","iter 200 train loss = 3.0809395721817276\n","200\n","iter 300 train loss = 3.0862969523566544\n","300\n","iter 400 train loss = 3.085256822110546\n","400\n","iter 500 train loss = 3.0881249642618736\n","500\n","iter 600 train loss = 3.0859476279949623\n","600\n","iter 700 train loss = 3.0843521072398543\n","700\n","iter 800 train loss = 3.0892058259435724\n","800\n","Epoch 4 valid loss = 4.145604563337545\n","iter 0 train loss = 3.074489859647529\n","0\n","iter 100 train loss = 3.082615148728059\n","100\n","iter 200 train loss = 3.076047891931889\n","200\n","iter 300 train loss = 3.0815255785309765\n","300\n","iter 400 train loss = 3.084878537397561\n","400\n","iter 500 train loss = 3.0829905347284594\n","500\n","iter 600 train loss = 3.0827319861232096\n","600\n","iter 700 train loss = 3.087474751682633\n","700\n","iter 800 train loss = 3.0896558579503344\n","800\n","Epoch 5 valid loss = 4.145604607984013\n","iter 0 train loss = 3.1241964285714285\n","0\n","iter 100 train loss = 3.103847671757682\n","100\n","iter 200 train loss = 3.1031247702478395\n","200\n","iter 300 train loss = 3.0956814457720996\n","300\n","iter 400 train loss = 3.09351125926818\n","400\n","iter 500 train loss = 3.0883061114189956\n","500\n","iter 600 train loss = 3.087986517111761\n","600\n","iter 700 train loss = 3.0882391233511384\n","700\n","iter 800 train loss = 3.0889837636193835\n","800\n","Epoch 6 valid loss = 4.145604571251467\n","iter 0 train loss = 3.1961337246737638\n","0\n","iter 100 train loss = 3.096480278607279\n","100\n","iter 200 train loss = 3.085948145787911\n","200\n","iter 300 train loss = 3.0859233877057486\n","300\n","iter 400 train loss = 3.0951885463918463\n","400\n","iter 500 train loss = 3.097480831751925\n","500\n","iter 600 train loss = 3.0968148484911038\n","600\n","iter 700 train loss = 3.093217845707221\n","700\n","iter 800 train loss = 3.0913741144675173\n","800\n","Epoch 7 valid loss = 4.145604570504871\n","iter 0 train loss = 3.140735626220703\n","0\n","iter 100 train loss = 3.0877237364248025\n","100\n","iter 200 train loss = 3.089608029362932\n","200\n","iter 300 train loss = 3.087337046097441\n","300\n","iter 400 train loss = 3.0838690994913915\n","400\n","iter 500 train loss = 3.0864985369629836\n","500\n","iter 600 train loss = 3.089427919528677\n","600\n","iter 700 train loss = 3.0877354502379046\n","700\n","iter 800 train loss = 3.0880284512597864\n","800\n","Epoch 8 valid loss = 4.1456045809572215\n","iter 0 train loss = 3.154252769303148\n","0\n","iter 100 train loss = 3.1099881022806475\n","100\n","iter 200 train loss = 3.0980906992734973\n","200\n","iter 300 train loss = 3.0892969787448656\n","300\n","iter 400 train loss = 3.092454897025064\n","400\n","iter 500 train loss = 3.0925132716714034\n","500\n","iter 600 train loss = 3.088493604258171\n","600\n","iter 700 train loss = 3.0906942232105834\n","700\n","iter 800 train loss = 3.090063868006891\n","800\n","Epoch 9 valid loss = 4.145604557066135\n","iter 0 train loss = 3.282064413964599\n","0\n","iter 100 train loss = 3.090343596753114\n","100\n","iter 200 train loss = 3.0904261508961244\n","200\n","iter 300 train loss = 3.0986255593119116\n","300\n","iter 400 train loss = 3.095650026781591\n","400\n","iter 500 train loss = 3.0965420683268934\n","500\n","iter 600 train loss = 3.0955539668343492\n","600\n","iter 700 train loss = 3.095984258644512\n","700\n","iter 800 train loss = 3.090566159754382\n","800\n","Epoch 10 valid loss = 4.145604600518048\n","iter 0 train loss = 3.2394327253303272\n","0\n","iter 100 train loss = 3.0755095888794832\n","100\n","iter 200 train loss = 3.0789305421284268\n","200\n","iter 300 train loss = 3.089138569140813\n","300\n","iter 400 train loss = 3.086603976171949\n","400\n","iter 500 train loss = 3.0887578236287125\n","500\n","iter 600 train loss = 3.0866372225834993\n","600\n","iter 700 train loss = 3.0902168812717945\n","700\n","iter 800 train loss = 3.089365197213336\n","800\n","Epoch 11 valid loss = 4.145604578941411\n","iter 0 train loss = 3.1204165810032896\n","0\n","iter 100 train loss = 3.0699678972271127\n","100\n","iter 200 train loss = 3.091056522843692\n","200\n","iter 300 train loss = 3.095295257366018\n","300\n","iter 400 train loss = 3.0905692091232972\n","400\n","iter 500 train loss = 3.0909544004809826\n","500\n","iter 600 train loss = 3.091187105356487\n","600\n","iter 700 train loss = 3.0897311918012575\n","700\n","iter 800 train loss = 3.0881225425192302\n","800\n","Epoch 12 valid loss = 4.145604530188662\n","iter 0 train loss = 2.9726336841851895\n","0\n","iter 100 train loss = 3.0568289132755826\n","100\n","iter 200 train loss = 3.073134488224828\n","200\n","iter 300 train loss = 3.078906084120513\n","300\n","iter 400 train loss = 3.0832584532719625\n","400\n","iter 500 train loss = 3.086044328785751\n","500\n","iter 600 train loss = 3.088856523091814\n","600\n","iter 700 train loss = 3.0895583386818495\n","700\n","iter 800 train loss = 3.0914057264828148\n","800\n","Epoch 13 valid loss = 4.145604585735438\n","iter 0 train loss = 3.0621354275901846\n","0\n","iter 100 train loss = 3.086009364454146\n","100\n","iter 200 train loss = 3.095333332348244\n","200\n","iter 300 train loss = 3.0976095932836136\n","300\n","iter 400 train loss = 3.0927538060704904\n","400\n","iter 500 train loss = 3.092431637857987\n","500\n","iter 600 train loss = 3.088296583293984\n","600\n","iter 700 train loss = 3.086736854515285\n","700\n","iter 800 train loss = 3.0901844036054262\n","800\n","Epoch 14 valid loss = 4.14560454332876\n","iter 0 train loss = 2.8393570178656407\n","0\n","iter 100 train loss = 3.0842263125995095\n","100\n","iter 200 train loss = 3.088292865347917\n","200\n","iter 300 train loss = 3.07895590312801\n","300\n","iter 400 train loss = 3.0842600123311925\n","400\n","iter 500 train loss = 3.0876473733554906\n","500\n","iter 600 train loss = 3.0888440171660863\n","600\n","iter 700 train loss = 3.088938546275148\n","700\n","iter 800 train loss = 3.089514977140564\n","800\n","Epoch 15 valid loss = 4.1456045753204185\n","iter 0 train loss = 2.980465232123559\n","0\n","iter 100 train loss = 3.0916011538572024\n","100\n","iter 200 train loss = 3.1080020271070077\n","200\n","iter 300 train loss = 3.1006419095989086\n","300\n","iter 400 train loss = 3.0939441629395357\n","400\n","iter 500 train loss = 3.0922430823466605\n","500\n","iter 600 train loss = 3.092074970525621\n","600\n","iter 700 train loss = 3.090851048732755\n","700\n","iter 800 train loss = 3.0890940842524253\n","800\n","Epoch 16 valid loss = 4.14560462127343\n","iter 0 train loss = 3.014909548875762\n","0\n","iter 100 train loss = 3.1137916194808994\n","100\n","iter 200 train loss = 3.10401808025215\n","200\n","iter 300 train loss = 3.0958671592972173\n","300\n","iter 400 train loss = 3.089510645365928\n","400\n","iter 500 train loss = 3.0868949065237565\n","500\n","iter 600 train loss = 3.087435692715421\n","600\n","iter 700 train loss = 3.0885335579280047\n","700\n","iter 800 train loss = 3.0918174379300742\n","800\n","Epoch 17 valid loss = 4.145604603355115\n","iter 0 train loss = 2.8919398050604115\n","0\n","iter 100 train loss = 3.088579394984105\n","100\n","iter 200 train loss = 3.091236875981755\n","200\n","iter 300 train loss = 3.0907683929457614\n","300\n","iter 400 train loss = 3.092831674559867\n","400\n","iter 500 train loss = 3.0945480691630243\n","500\n","iter 600 train loss = 3.093274674370585\n","600\n","iter 700 train loss = 3.092705123878356\n","700\n","iter 800 train loss = 3.089872314704526\n","800\n","Epoch 18 valid loss = 4.145604567817124\n","iter 0 train loss = 3.165459722066097\n","0\n","iter 100 train loss = 3.0907907869046416\n","100\n","iter 200 train loss = 3.078411051957797\n","200\n","iter 300 train loss = 3.0840193813006334\n","300\n","iter 400 train loss = 3.0833677552118575\n","400\n","iter 500 train loss = 3.07839754281809\n","500\n","iter 600 train loss = 3.083189564185113\n","600\n","iter 700 train loss = 3.08809676538693\n","700\n","iter 800 train loss = 3.0897157727842726\n","800\n","Epoch 19 valid loss = 4.145604619481599\n","iter 0 train loss = 2.853350532772206\n","0\n","iter 100 train loss = 3.0789908815489415\n","100\n","iter 200 train loss = 3.0902367301955667\n","200\n","iter 300 train loss = 3.0884156233594355\n","300\n","iter 400 train loss = 3.0889349483346678\n","400\n","iter 500 train loss = 3.090015031934367\n","500\n","iter 600 train loss = 3.0889021104425884\n","600\n","iter 700 train loss = 3.092212621789725\n","700\n","iter 800 train loss = 3.089789836523442\n","800\n","Epoch 20 valid loss = 4.145604577373558\n","iter 0 train loss = 3.0423095162990874\n","0\n","iter 100 train loss = 3.107006425329389\n","100\n","iter 200 train loss = 3.084408013161912\n","200\n","iter 300 train loss = 3.0911348169570654\n","300\n","iter 400 train loss = 3.0897314903319595\n","400\n","iter 500 train loss = 3.089337866120628\n","500\n","iter 600 train loss = 3.0894118825899546\n","600\n","iter 700 train loss = 3.08952354019138\n","700\n","iter 800 train loss = 3.0922836877331696\n","800\n","Epoch 21 valid loss = 4.145604605744224\n","iter 0 train loss = 2.93458251953125\n","0\n","iter 100 train loss = 3.112231684227034\n","100\n","iter 200 train loss = 3.116488715306912\n","200\n","iter 300 train loss = 3.1066952294810335\n","300\n","iter 400 train loss = 3.1015620780045485\n","400\n","iter 500 train loss = 3.095610506981902\n","500\n","iter 600 train loss = 3.0951988348911854\n","600\n","iter 700 train loss = 3.0887447868783164\n","700\n","iter 800 train loss = 3.0889381950660026\n","800\n","Epoch 22 valid loss = 4.145604599472813\n","iter 0 train loss = 2.9872865460681677\n","0\n","iter 100 train loss = 3.0888587275854533\n","100\n","iter 200 train loss = 3.0953230323963017\n","200\n","iter 300 train loss = 3.094178088022937\n","300\n","iter 400 train loss = 3.0925211891704993\n","400\n","iter 500 train loss = 3.0919553750975486\n","500\n","iter 600 train loss = 3.0888033377737734\n","600\n","iter 700 train loss = 3.089095247847745\n","700\n","iter 800 train loss = 3.0902356504635056\n","800\n","Epoch 23 valid loss = 4.145604605744224\n","iter 0 train loss = 2.9809916338582676\n","0\n","iter 100 train loss = 3.079957063915873\n","100\n","iter 200 train loss = 3.078646983802607\n","200\n","iter 300 train loss = 3.0918535380896324\n","300\n","iter 400 train loss = 3.0929045481389097\n","400\n","iter 500 train loss = 3.0906093167343442\n","500\n","iter 600 train loss = 3.0903287941293875\n","600\n","iter 700 train loss = 3.0921332298709494\n","700\n","iter 800 train loss = 3.08983078821877\n","800\n","Epoch 24 valid loss = 4.145604583644968\n","iter 0 train loss = 3.1537767231758007\n","0\n","iter 100 train loss = 3.0848868032591796\n","100\n","iter 200 train loss = 3.089215545036532\n","200\n","iter 300 train loss = 3.090502319105819\n","300\n","iter 400 train loss = 3.094675735684375\n","400\n","iter 500 train loss = 3.094945595110436\n","500\n","iter 600 train loss = 3.0936748209809837\n","600\n","iter 700 train loss = 3.0933028382763004\n","700\n","iter 800 train loss = 3.08878310366625\n","800\n","Epoch 25 valid loss = 4.145604548405616\n","iter 0 train loss = 3.200686671152836\n","0\n","iter 100 train loss = 3.106816913905845\n","100\n","iter 200 train loss = 3.093119087859974\n","200\n","iter 300 train loss = 3.0860063371646187\n","300\n","iter 400 train loss = 3.0880362463545667\n","400\n","iter 500 train loss = 3.0863800515256976\n","500\n","iter 600 train loss = 3.088361223518832\n","600\n","iter 700 train loss = 3.088719291568662\n","700\n","iter 800 train loss = 3.0903288243215243\n","800\n","Epoch 26 valid loss = 4.145604544224676\n","iter 0 train loss = 3.162100853858056\n","0\n","iter 100 train loss = 3.113387680295522\n","100\n","iter 200 train loss = 3.103930237908476\n","200\n","iter 300 train loss = 3.097091166309085\n","300\n","iter 400 train loss = 3.0883066766376133\n","400\n","iter 500 train loss = 3.0914116409089596\n","500\n","iter 600 train loss = 3.093243525558876\n","600\n","iter 700 train loss = 3.0908934162228134\n","700\n","iter 800 train loss = 3.0889648856289442\n","800\n","Epoch 27 valid loss = 4.145604562441629\n","iter 0 train loss = 3.0606931636710923\n","0\n","iter 100 train loss = 3.0844876389809954\n","100\n","iter 200 train loss = 3.084299865287251\n","200\n","iter 300 train loss = 3.0855590196029428\n","300\n","iter 400 train loss = 3.0874855907175616\n","400\n","iter 500 train loss = 3.086420113162864\n","500\n","iter 600 train loss = 3.089574443917923\n","600\n","iter 700 train loss = 3.088464691727447\n","700\n","iter 800 train loss = 3.0888371991923638\n","800\n","Epoch 28 valid loss = 4.145604560948437\n","iter 0 train loss = 3.132062244175063\n","0\n","iter 100 train loss = 3.0842827216728583\n","100\n","iter 200 train loss = 3.084068634233656\n","200\n","iter 300 train loss = 3.0826814495618904\n","300\n","iter 400 train loss = 3.082216098508653\n","400\n","iter 500 train loss = 3.089234053594491\n","500\n","iter 600 train loss = 3.0870455367351957\n","600\n","iter 700 train loss = 3.0873748888489843\n","700\n","iter 800 train loss = 3.0883883585541807\n","800\n","Epoch 29 valid loss = 4.145604599920771\n","iter 0 train loss = 2.883601685948081\n","0\n","iter 100 train loss = 3.081917733760556\n","100\n","iter 200 train loss = 3.0823784452128\n","200\n","iter 300 train loss = 3.0827921556163673\n","300\n","iter 400 train loss = 3.095171706691046\n","400\n","iter 500 train loss = 3.0952745606505747\n","500\n","iter 600 train loss = 3.092671426894916\n","600\n","iter 700 train loss = 3.0916032650712038\n","700\n","iter 800 train loss = 3.0903102190347562\n","800\n","Epoch 30 valid loss = 4.145604611716996\n","iter 0 train loss = 3.1198581771202196\n","0\n","iter 100 train loss = 3.1007286946654316\n","100\n","iter 200 train loss = 3.0963896852860335\n","200\n","iter 300 train loss = 3.089463286065695\n","300\n","iter 400 train loss = 3.0886994419893\n","400\n","iter 500 train loss = 3.0829512338114795\n","500\n","iter 600 train loss = 3.08973622247914\n","600\n","iter 700 train loss = 3.0882036449823644\n","700\n","iter 800 train loss = 3.0895023067322693\n","800\n","Epoch 31 valid loss = 4.145604572371362\n","iter 0 train loss = 3.2757770685859806\n","0\n","iter 100 train loss = 3.0734925612961312\n","100\n","iter 200 train loss = 3.0770186835625912\n","200\n","iter 300 train loss = 3.082767558198541\n","300\n","iter 400 train loss = 3.083511520590796\n","400\n","iter 500 train loss = 3.0864342130425593\n","500\n","iter 600 train loss = 3.0834800349371054\n","600\n","iter 700 train loss = 3.0900773207738883\n","700\n","iter 800 train loss = 3.088519843407776\n","800\n","Epoch 32 valid loss = 4.145604571550106\n","iter 0 train loss = 3.079253947391214\n","0\n","iter 100 train loss = 3.1025647035029498\n","100\n","iter 200 train loss = 3.1023763699321636\n","200\n","iter 300 train loss = 3.0990542280177857\n","300\n","iter 400 train loss = 3.0933371081521317\n","400\n","iter 500 train loss = 3.090413381685972\n","500\n","iter 600 train loss = 3.090966202591276\n","600\n","iter 700 train loss = 3.091905117616186\n","700\n","iter 800 train loss = 3.091112364514948\n","800\n","Epoch 33 valid loss = 4.145604559604563\n","iter 0 train loss = 2.746097449100379\n","0\n","iter 100 train loss = 3.0914480190722227\n","100\n","iter 200 train loss = 3.0899767216527065\n","200\n","iter 300 train loss = 3.088214123557408\n","300\n","iter 400 train loss = 3.094468293347526\n","400\n","iter 500 train loss = 3.094886345266975\n","500\n","iter 600 train loss = 3.0912651550425694\n","600\n","iter 700 train loss = 3.092094475493828\n","700\n","iter 800 train loss = 3.0908645236481416\n","800\n","Epoch 34 valid loss = 4.145604558260689\n","iter 0 train loss = 3.1004169521047107\n","0\n","iter 100 train loss = 3.105419508985763\n","100\n","iter 200 train loss = 3.1039351547688954\n","200\n","iter 300 train loss = 3.103074276597734\n","300\n","iter 400 train loss = 3.1021891529696246\n","400\n","iter 500 train loss = 3.0942357448441156\n","500\n","iter 600 train loss = 3.0914727528022476\n","600\n","iter 700 train loss = 3.091190329852019\n","700\n","iter 800 train loss = 3.0909062791094355\n","800\n","Epoch 35 valid loss = 4.145604590364337\n","iter 0 train loss = 2.9129513085133745\n","0\n","iter 100 train loss = 3.108910820844983\n","100\n","iter 200 train loss = 3.089396741880271\n","200\n","iter 300 train loss = 3.0859352295406626\n","300\n","iter 400 train loss = 3.0831603995363315\n","400\n","iter 500 train loss = 3.084969754182045\n","500\n","iter 600 train loss = 3.08461141855964\n","600\n","iter 700 train loss = 3.088963698549061\n","700\n","iter 800 train loss = 3.0899755336836803\n","800\n","Epoch 36 valid loss = 4.145604589319102\n","iter 0 train loss = 2.9185146252550074\n","0\n","iter 100 train loss = 3.0775301402738626\n","100\n","iter 200 train loss = 3.0896319156305476\n","200\n","iter 300 train loss = 3.0874125626839635\n","300\n","iter 400 train loss = 3.087669567203428\n","400\n","iter 500 train loss = 3.0873954636761773\n","500\n","iter 600 train loss = 3.088888013809293\n","600\n","iter 700 train loss = 3.0939620537420685\n","700\n","iter 800 train loss = 3.091272419583137\n","800\n","Epoch 37 valid loss = 4.145604624259816\n","iter 0 train loss = 3.191672258836063\n","0\n","iter 100 train loss = 3.107711241410615\n","100\n","iter 200 train loss = 3.102687406109773\n","200\n","iter 300 train loss = 3.1012789386945667\n","300\n","iter 400 train loss = 3.0918237850829717\n","400\n","iter 500 train loss = 3.0904512003106803\n","500\n","iter 600 train loss = 3.0893715955038386\n","600\n","iter 700 train loss = 3.089405718574314\n","700\n","iter 800 train loss = 3.0899671876230204\n","800\n","Epoch 38 valid loss = 4.145604602011241\n","iter 0 train loss = 3.1081171875\n","0\n","iter 100 train loss = 3.10221937979288\n","100\n","iter 200 train loss = 3.097568733801254\n","200\n","iter 300 train loss = 3.1000012047773895\n","300\n","iter 400 train loss = 3.0928271902723283\n","400\n","iter 500 train loss = 3.092482798459982\n","500\n","iter 600 train loss = 3.08957529948995\n","600\n","iter 700 train loss = 3.090477122729076\n","700\n","iter 800 train loss = 3.089669027937215\n","800\n","Epoch 39 valid loss = 4.145604561247075\n","iter 0 train loss = 3.2154220920138887\n","0\n","iter 100 train loss = 3.083882120647551\n","100\n","iter 200 train loss = 3.0675889388100184\n","200\n","iter 300 train loss = 3.0739869908145057\n","300\n","iter 400 train loss = 3.0800887151432996\n","400\n","iter 500 train loss = 3.085674583729067\n","500\n","iter 600 train loss = 3.08921477798106\n","600\n","iter 700 train loss = 3.0884303089128604\n","700\n","iter 800 train loss = 3.090152693337233\n","800\n","Epoch 40 valid loss = 4.145604556468857\n","iter 0 train loss = 3.0873145165381493\n","0\n","iter 100 train loss = 3.0665234133070673\n","100\n","iter 200 train loss = 3.1010546083307036\n","200\n","iter 300 train loss = 3.0890078197243334\n","300\n","iter 400 train loss = 3.089373962080999\n","400\n","iter 500 train loss = 3.0900406618163423\n","500\n","iter 600 train loss = 3.0883736190200506\n","600\n","iter 700 train loss = 3.0888163278540786\n","700\n","iter 800 train loss = 3.088405605064994\n","800\n","Epoch 41 valid loss = 4.145604599622133\n","iter 0 train loss = 3.0356498571798647\n","0\n","iter 100 train loss = 3.098157795642023\n","100\n","iter 200 train loss = 3.0966770560948738\n","200\n","iter 300 train loss = 3.092641840705597\n","300\n","iter 400 train loss = 3.090208146921927\n","400\n","iter 500 train loss = 3.088589163810493\n","500\n","iter 600 train loss = 3.089582391227302\n","600\n","iter 700 train loss = 3.0908181975789777\n","700\n","iter 800 train loss = 3.089973321590057\n","800\n","Epoch 42 valid loss = 4.145604573192618\n","iter 0 train loss = 2.955345172646605\n","0\n","iter 100 train loss = 3.071364742690199\n","100\n","iter 200 train loss = 3.0850118146540564\n","200\n","iter 300 train loss = 3.087094530082266\n","300\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iQjSRL6jF7oK"},"source":["# **Loss Plots**"]},{"cell_type":"code","metadata":{"id":"GBs1t43IIFAG"},"source":["#just show plot cache for fine-tuning part and not Phase 1\n","plot_cache = plot_cache[-12:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3et1oKnIeiT","executionInfo":{"status":"ok","timestamp":1606101890316,"user_tz":300,"elapsed":774,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"65ba445d-d389-4ba4-d923-92578dfdbb18"},"source":["plot_cache"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(3.0891070594586596, 4.145604575880365),\n"," (3.089356815162547, 4.1456045645321),\n"," (3.0901333028641695, 4.145604559753882),\n"," (3.0892058259435724, 4.145604563337545),\n"," (3.0896558579503344, 4.145604607984013),\n"," (3.0889837636193835, 4.145604571251467),\n"," (3.0913741144675173, 4.145604570504871),\n"," (3.0880284512597864, 4.1456045809572215),\n"," (3.090063868006891, 4.145604557066135),\n"," (3.090566159754382, 4.145604600518048),\n"," (3.089365197213336, 4.145604578941411),\n"," (3.0881225425192302, 4.145604530188662)]"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"FZkucGW2iyRP","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1606101878950,"user_tz":300,"elapsed":465,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"2d2c46cd-d300-42ca-df92-3309218ac9fb"},"source":["import numpy as np\n","epochs = np.array(list(range(len(plot_cache))))\n","plt.plot(epochs, [i[0] for i in plot_cache], label='Train loss')\n","plt.plot(epochs, [i[1] for i in plot_cache], label='Valid loss')\n","\n","plt.legend()\n","plt.title('Loss curves')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"kAK43ulYizPd","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1606101913661,"user_tz":300,"elapsed":767,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"66851f49-7238-41e7-9ade-3a094dc01602"},"source":["epochs = np.array(list(range(len(plot_cache))))\n","plt.plot(epochs, [2**(i[0]/np.log(2)) for i in plot_cache], label='Train ppl')\n","plt.plot(epochs, [2**(i[1]/np.log(2)) for i in plot_cache], label='Valid ppl')\n","\n","plt.legend()\n","plt.title('PPL curves')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Z7-TAtVwE5wO","executionInfo":{"status":"ok","timestamp":1606518582781,"user_tz":300,"elapsed":519,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}}},"source":["plot_cache = [(3.0891070594586596, 4.145604575880365),\n"," (3.089356815162547, 4.1456045645321),\n"," (3.0901333028641695, 4.145604559753882),\n"," (3.0892058259435724, 4.145604563337545),\n"," (3.0896558579503344, 4.145604607984013),\n"," (3.0889837636193835, 4.145604571251467),\n"," (3.0913741144675173, 4.145604570504871),\n"," (3.0880284512597864, 4.1456045809572215),\n"," (3.090063868006891, 4.145604557066135),\n"," (3.090566159754382, 4.145604600518048),\n"," (3.089365197213336, 4.145604578941411),\n"," (3.0881225425192302, 4.145604530188662)]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3-aDB6a-ApU","executionInfo":{"status":"ok","timestamp":1606518626208,"user_tz":300,"elapsed":436,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}}},"source":["import numpy as np\n","ppl = [2**(i[1]/np.log(2)) for i in plot_cache]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVgMI2Nj-LlP","executionInfo":{"status":"ok","timestamp":1606518628594,"user_tz":300,"elapsed":235,"user":{"displayName":"Amanda Kuznecov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWqCM-4eoQkiUBQFArDW57WqZyJdN1BVRKe01O=s64","userId":"10709662812019526205"}},"outputId":"0f200b28-8aff-4b18-a2fd-b01a088df7f9","colab":{"base_uri":"https://localhost:8080/"}},"source":["ppl"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[63.15579283102177,\n"," 63.155792114313094,\n"," 63.15579181254094,\n"," 63.155792038870054,\n"," 63.15579485855313,\n"," 63.155792538680046,\n"," 63.1557924915282,\n"," 63.155793151654656,\n"," 63.15579164279418,\n"," 63.1557943870342,\n"," 63.15579302434454,\n"," 63.155789945326134]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"KZtCT7Ry-N_M"},"source":[""],"execution_count":null,"outputs":[]}]}